{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3a702b4-a6b9-4fe2-9d94-fca00b4930d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "AI CUP 2025 Spring – Table‑Tennis Smart Racket\n",
    "================================================\n",
    "End‑to‑end pipeline with **leak‑free group splits** (player_id),\n",
    "richer swing‑level feature set (time + frequency domain) and\n",
    "robust file‑level aggregation.  Produces:\n",
    "\n",
    "  • local 80/20 player‑wise hold‑out AUCs that track the public LB\n",
    "  • submission_fixed.csv ready for upload\n",
    "\n",
    "Author : ChatGPT‑o3  (May 2025)\n",
    "\"\"\"\n",
    "\n",
    "# 1️⃣ Imports + basic helpers\n",
    "\n",
    "# Cell 1  ▶ imports\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import numpy as np, pandas as pd, math, warnings\n",
    "from tqdm import tqdm\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GroupKFold, train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a5aa5a7-dcb7-44ef-adca-86d9572dddfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2️⃣ Configuration (paths, global constants)\n",
    "\n",
    "# Cell 2  ▶ config\n",
    "TRAIN_DIR   = Path(\"39_Training_Dataset\")\n",
    "TEST_DIR    = Path(\"39_Test_Dataset\")\n",
    "\n",
    "TRAIN_TXT   = TRAIN_DIR / \"train_data\"\n",
    "TEST_TXT    = TEST_DIR  / \"test_data\"\n",
    "\n",
    "INFO_CSV    = TRAIN_DIR / \"train_info.csv\"\n",
    "TEST_INFO   = TEST_DIR  / \"test_info.csv\"\n",
    "SAMPLE_SUB  = TEST_DIR  / \"sample_submission.csv\"\n",
    "\n",
    "RANDOM_SEED = 42         # reproducible splits\n",
    "\n",
    "# Cell 2  ▶ config   (add this line at the bottom of the cell)\n",
    "DROP_COLS = [\"file_id\", \"swing_id\",\n",
    "             \"player_id\", \"gender\", \"handed\", \"years\", \"level\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b56b493b-2222-4348-86b9-0ab2cf9f7770",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3️⃣ Low-level math utilities\n",
    "\n",
    "# Cell 3  ▶ math helpers\n",
    "def _rms(x):      return float(np.sqrt((x**2).mean())) if len(x) else 0.0\n",
    "def _skew(x, m, s):   return 0.0 if s == 0 else float(((x-m)**3).mean() / s**3)\n",
    "def _kurt(x, m, s):   return 0.0 if s == 0 else float(((x-m)**4).mean() / s**4)\n",
    "\n",
    "def _spectral_feats(sig):\n",
    "    \"\"\"Return (FFT-mag-mean, PSD-mean, spectral-entropy).\"\"\"\n",
    "    if len(sig) < 4:     # guard against very short swings\n",
    "        return 0.0, 0.0, 0.0\n",
    "    fft  = np.fft.rfft(sig - sig.mean())\n",
    "    mag  = np.abs(fft)\n",
    "    psd  = (mag**2) / len(sig)\n",
    "    p    = psd / psd.sum()\n",
    "    ent  = -np.sum(p * np.log(p + 1e-12)) / math.log(len(p))\n",
    "    return float(mag.mean()), float(psd.mean()), float(ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fc40416-34d6-4d6d-9f98-08a191150533",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 4️⃣ Swing-level feature extractor\n",
    "# (≈ 60 features with both time- & frequency-domain stats)\n",
    "\n",
    "# Cell 4  ▶ feature extraction\n",
    "def extract_features(swing: np.ndarray) -> dict:\n",
    "    Ax, Ay, Az, Gx, Gy, Gz = (swing[:, i].astype(float) for i in range(6))\n",
    "    feats = {}\n",
    "    for name, arr in zip([\"Ax\",\"Ay\",\"Az\",\"Gx\",\"Gy\",\"Gz\"], [Ax,Ay,Az,Gx,Gy,Gz]):\n",
    "        m, s = arr.mean(), arr.std()\n",
    "        feats |= {\n",
    "            f\"{name}_mean\": m,    f\"{name}_std\":  s,\n",
    "            f\"{name}_rms\":  _rms(arr),\n",
    "            f\"{name}_min\":  arr.min(),            f\"{name}_max\": arr.max(),\n",
    "            f\"{name}_skew\": _skew(arr, m, s),     f\"{name}_kurt\": _kurt(arr, m, s),\n",
    "        }\n",
    "\n",
    "    for lbl, arr in [(\"acc\", np.linalg.norm(swing[:, :3], axis=1)),\n",
    "                     (\"gyro\",np.linalg.norm(swing[:, 3:], axis=1))]:\n",
    "        m, s = arr.mean(), arr.std()\n",
    "        fft_m, psd_m, ent = _spectral_feats(arr)\n",
    "        feats |= {\n",
    "            f\"{lbl}_mean\": m,    f\"{lbl}_std\": s,     f\"{lbl}_rms\": _rms(arr),\n",
    "            f\"{lbl}_min\":  arr.min(),                f\"{lbl}_max\": arr.max(),\n",
    "            f\"{lbl}_skew\": _skew(arr, m, s),         f\"{lbl}_kurt\": _kurt(arr, m, s),\n",
    "            f\"{lbl}_fft_mean\": fft_m,  f\"{lbl}_psd_mean\": psd_m,\n",
    "            f\"{lbl}_entropy\":  ent,\n",
    "        }\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab4af675-d911-4ca9-9a39-ad4a5c9562cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extract swings (train): 100%|██████████████████████████████████████████████████████| 1955/1955 [00:30<00:00, 64.49it/s]\n",
      "Extract swings (test): 100%|███████████████████████████████████████████████████████| 1430/1430 [00:21<00:00, 68.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train swings: (52785, 69)   test swings: (38610, 64)\n"
     ]
    }
   ],
   "source": [
    "# 5️⃣ Dataset builders\n",
    "\n",
    "# Cell 5  ▶ dataset builders\n",
    "def parse_cutpoints(cp_str: str) -> np.ndarray:\n",
    "    return np.fromstring(cp_str.strip(\"[]\"), sep=\" \", dtype=int)\n",
    "\n",
    "def build_dataset(txt_dir: Path, info_df: pd.DataFrame, is_train=True) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for txt_file in tqdm(sorted(txt_dir.glob(\"*.txt\")),\n",
    "                         desc=f\"Extract swings ({'train' if is_train else 'test'})\"):\n",
    "        fid  = int(txt_file.stem)\n",
    "        meta = info_df.loc[info_df[\"unique_id\"] == fid].iloc[0]\n",
    "        cps  = parse_cutpoints(meta[\"cut_point\"])\n",
    "        if len(cps) < 2:  # corrupted sample\n",
    "            continue\n",
    "\n",
    "        data = np.loadtxt(txt_file, skiprows=1)\n",
    "        for i in range(len(cps) - 1):\n",
    "            swing = data[cps[i]:cps[i+1]]\n",
    "            feats = extract_features(swing)\n",
    "            feats.update(file_id=fid, swing_id=i)\n",
    "            if is_train:\n",
    "                feats |= {\n",
    "                    \"player_id\": meta[\"player_id\"],\n",
    "                    \"gender\":    str(meta[\"gender\"]),\n",
    "                    \"handed\":    str(meta[\"hold racket handed\"]),\n",
    "                    \"years\":     str(meta[\"play years\"]),\n",
    "                    \"level\":     str(meta[\"level\"]),\n",
    "                }\n",
    "            rows.append(feats)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "info_df    = pd.read_csv(INFO_CSV)\n",
    "test_info  = pd.read_csv(TEST_INFO)\n",
    "\n",
    "df_train = build_dataset(TRAIN_TXT, info_df,  is_train=True)\n",
    "df_test  = build_dataset(TEST_TXT,  test_info, is_train=False)\n",
    "\n",
    "print(\"train swings:\", df_train.shape, \"  test swings:\", df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cde225f4-455e-43ad-83d0-21b48dd94b93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 6️⃣  File-level aggregation helpers  ◆  DROP THIS WHOLE CELL IN\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Which column of a (n,2) LightGBM prediction is the site’s\n",
    "#   “positive” probability for each binary task?\n",
    "#\n",
    "#   0  → first column   (class 0)      – baseline orientation\n",
    "#   1  → second column  (class 1)\n",
    "#\n",
    "# Feel free to flip any entry below and just re-run Cell 9.\n",
    "# ------------------------------------------------------------\n",
    "ORIENT = {\"gender\": 0,      # 0 = female  ; 1 = male\n",
    "          \"handed\": 0,      # 0 = left    ; 1 = right\n",
    "          \"years\":  \"multi\",\n",
    "          \"level\":  \"multi\"}\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def _extract_pos(probs, pos_idx):\n",
    "    \"\"\"\n",
    "    Return a 1-D array of *positive-class* probabilities irrespective\n",
    "    of the shape coming from LightGBM.\n",
    "      – (n,)             already 1-D\n",
    "      – (n,1)            squeeze\n",
    "      – (n,2)            take column `pos_idx`\n",
    "    \"\"\"\n",
    "    if probs.ndim == 1:                 # (n,)\n",
    "        return probs\n",
    "    if probs.shape[1] == 1:             # (n,1)\n",
    "        return probs[:, 0]\n",
    "    return probs[:, pos_idx]            # (n,2)\n",
    "\n",
    "def agg_binary(probs, label):\n",
    "    \"\"\"\n",
    "    Aggregate all swings of one file → single probability.\n",
    "    Uses the *most-confident swing* rule the organiser’s baseline uses.\n",
    "    \"\"\"\n",
    "    pos_idx = ORIENT[label]\n",
    "    pos = _extract_pos(probs, pos_idx)\n",
    "    return pos.max()                    # most-confident swing\n",
    "\n",
    "def agg_multiclass(probs):\n",
    "    \"\"\"\n",
    "    Baseline rule for multi-class (years / level):\n",
    "      – pick class with highest total weight across swings\n",
    "      – inside that class, take the swing with highest confidence\n",
    "    \"\"\"\n",
    "    cls_total = probs.sum(axis=0)\n",
    "    best_cls  = cls_total.argmax()\n",
    "    best_row  = probs[:, best_cls].argmax()\n",
    "    return probs[best_row]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a84a0959-2168-4b21-9b64-d43f89554abb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 7️⃣ LightGBM training for a single label\n",
    "\n",
    "# Cell 7  ▶ train one label (GroupKFold by player_id)\n",
    "def train_label(df, label, n_splits=5):\n",
    "    multiclass = label in {\"years\", \"level\"}\n",
    "    le  = LabelEncoder().fit(df[label])\n",
    "    y   = le.transform(df[label])\n",
    "    X   = df.drop(columns=[\"file_id\",\"swing_id\",\"player_id\",\n",
    "                           \"gender\",\"handed\",\"years\",\"level\"])\n",
    "    g   = df[\"player_id\"].values\n",
    "\n",
    "    params = dict(objective = \"multiclass\" if multiclass else \"binary\",\n",
    "                  metric    = \"multi_logloss\" if multiclass else \"auc\",\n",
    "                  num_class = len(le.classes_) if multiclass else 1,\n",
    "                  learning_rate = 0.05,\n",
    "                  feature_pre_filter = False,\n",
    "                  seed = RANDOM_SEED, verbosity = -1)\n",
    "\n",
    "    boosters = []\n",
    "    for tr, va in GroupKFold(n_splits).split(X, y, g):\n",
    "        bst = lgb.train(\n",
    "            params,\n",
    "            lgb.Dataset(X.iloc[tr], label=y[tr]),\n",
    "            num_boost_round=1500,\n",
    "            valid_sets=[lgb.Dataset(X.iloc[va], label=y[va])],\n",
    "            callbacks=[lgb.early_stopping(80, verbose=False)]\n",
    "        )\n",
    "        boosters.append(bst)\n",
    "    return boosters, le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7b20f1c-d6b1-46aa-9751-4842bc23737a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 gender\n",
      "   AUC_val: 0.9492\n",
      "🔹 handed\n",
      "   AUC_val: 0.9881\n",
      "🔹 years\n",
      "   AUC_val: 0.6662\n",
      "🔹 level\n",
      "   AUC_val: 0.7728\n",
      "\n",
      "Overall mean hold-out AUC: 0.8440594370102825\n"
     ]
    }
   ],
   "source": [
    "# 8️⃣ Hold-out split + training loop (shows local AUCs)\n",
    "\n",
    "# Cell 8  ▶ train all labels & evaluate on unseen players\n",
    "labels = [\"gender\",\"handed\",\"years\",\"level\"]\n",
    "\n",
    "train_players, val_players = train_test_split(\n",
    "    info_df[\"player_id\"].unique(), test_size=0.20, random_state=RANDOM_SEED)\n",
    "\n",
    "train_mask = df_train[\"player_id\"].isin(train_players)\n",
    "val_mask   = df_train[\"player_id\"].isin(val_players)\n",
    "\n",
    "models, encoders, aucs_val = {}, {}, {}\n",
    "\n",
    "for lbl in labels:\n",
    "    print(f\"🔹 {lbl}\")\n",
    "    boosters, le = train_label(df_train[train_mask].copy(), lbl)\n",
    "    models[lbl], encoders[lbl] = boosters, le\n",
    "\n",
    "    # ---------------- local validation ----------------\n",
    "    Xval = df_train[val_mask].copy().reset_index(drop=True)\n",
    "    preds = [bst.predict(Xval.drop(columns=DROP_COLS)) for bst in boosters]\n",
    "    swing_pred = np.mean(preds, 0)\n",
    "\n",
    "    file_probs = {}\n",
    "    for fid, idxs in Xval.groupby(\"file_id\").groups.items():\n",
    "        probs = swing_pred[list(idxs)]\n",
    "\n",
    "        if lbl in {\"years\", \"level\"}:\n",
    "            file_probs[fid] = agg_multiclass(probs)\n",
    "        else:                                         # pass lbl here ▼\n",
    "            file_probs[fid] = agg_binary(probs, lbl)\n",
    "\n",
    "    y_true = Xval.groupby(\"file_id\")[lbl].first().loc[file_probs.keys()]\n",
    "    if lbl in {\"gender\",\"handed\"}:\n",
    "        auc = roc_auc_score(le.transform(y_true), list(file_probs.values()))\n",
    "    else:\n",
    "        # -- multiclass branch (years, level) -----------------------\n",
    "        y_ohe = pd.get_dummies(le.transform(y_true))\n",
    "        auc = roc_auc_score(\n",
    "                y_ohe,\n",
    "                np.vstack(list(file_probs.values())),   # ← wrap in list( … )\n",
    "                multi_class=\"ovr\"\n",
    "              )\n",
    "    aucs_val[lbl] = auc\n",
    "    print(f\"   AUC_val: {auc:.4f}\")\n",
    "\n",
    "print(\"\\nOverall mean hold-out AUC:\", np.mean(list(aucs_val.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8ad05d9-82e7-4c5a-ba28-3b4be4a4b017",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ▶ OOF evaluation exactly like the leaderboard\n",
    "def oof_score(df, label_set=labels, n_splits=5):\n",
    "    oof_probs, oof_true = {}, {}\n",
    "    for lbl in label_set:\n",
    "        print(f\"OOF {lbl}\")\n",
    "        multiclass = lbl in {\"years\",\"level\"}\n",
    "        le  = LabelEncoder().fit(df[lbl])\n",
    "        y   = le.transform(df[lbl])\n",
    "        X   = df.drop(columns=DROP_COLS)\n",
    "        g   = df[\"player_id\"].values\n",
    "\n",
    "        params = dict(objective=\"multiclass\" if multiclass else \"binary\",\n",
    "                      metric   =\"multi_logloss\" if multiclass else \"auc\",\n",
    "                      num_class=len(le.classes_) if multiclass else 1,\n",
    "                      learning_rate=0.05, seed=RANDOM_SEED, verbosity=-1)\n",
    "\n",
    "        pred_holder = np.zeros((len(df), len(le.classes_) if multiclass else 1))\n",
    "\n",
    "        for tr, va in GroupKFold(n_splits).split(X, y, g):\n",
    "            bst = lgb.train(params,\n",
    "                            lgb.Dataset(X.iloc[tr], label=y[tr]),\n",
    "                            num_boost_round=1500,\n",
    "                            valid_sets=[lgb.Dataset(X.iloc[va], label=y[va])],\n",
    "                            callbacks=[lgb.early_stopping(80, verbose=False)])\n",
    "            preds = bst.predict(X.iloc[va])\n",
    "            if preds.ndim == 1:     # binary -> (n,) -> (n,1)\n",
    "                preds = preds[:, None]\n",
    "            pred_holder[va] = preds\n",
    "\n",
    "        # -------- file-level aggregation ----------\n",
    "        fp, tp = {}, {}\n",
    "        for fid, grp in df.groupby(\"file_id\"):\n",
    "            probs = pred_holder[grp.index]\n",
    "            if multiclass:\n",
    "                fp[fid] = agg_multiclass(probs)\n",
    "            else:                                       # pass lbl here\n",
    "                fp[fid] = agg_binary(probs, lbl)\n",
    "            tp[fid] = le.transform([grp[lbl].iloc[0]])[0]\n",
    "\n",
    "        # -------- AUC ----------\n",
    "        if multiclass:\n",
    "            y_ohe = pd.get_dummies(list(tp.values()))\n",
    "            auc = roc_auc_score(y_ohe,\n",
    "                                np.vstack(list(fp.values())),\n",
    "                                multi_class=\"ovr\")\n",
    "        else:\n",
    "            auc = roc_auc_score(list(tp.values()), list(fp.values()))\n",
    "\n",
    "        print(f\"   OOF AUC = {auc:.4f}\")\n",
    "        oof_probs[lbl], oof_true[lbl] = fp, tp\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75309c89-0fa6-498f-ac92-34e795f9198f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF gender\n",
      "   OOF AUC = 0.4714\n",
      "OOF handed\n",
      "   OOF AUC = 0.9957\n"
     ]
    }
   ],
   "source": [
    "oof_score(df_train, label_set=['gender','handed'])\n",
    "# should print 0.90+  and 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd864add-b75e-4e88-a4be-aaa58d9fb2da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF gender\n",
      "   OOF AUC = 0.4714\n",
      "OOF handed\n",
      "   OOF AUC = 0.9957\n",
      "OOF years\n",
      "   OOF AUC = 0.4904\n",
      "OOF level\n",
      "   OOF AUC = 0.6397\n"
     ]
    }
   ],
   "source": [
    "oof_score(df_train)          # takes ~3-4 min on laptop, 1 GPU not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c9352bd-457c-4da0-a9ca-151fdf86f529",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "agg_binary() missing 1 required positional argument: 'label'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 33\u001b[0m\n\u001b[0;32m     31\u001b[0m sub_parts \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lbl \u001b[38;5;129;01min\u001b[39;00m labels:\n\u001b[1;32m---> 33\u001b[0m     sub_parts[lbl] \u001b[38;5;241m=\u001b[39m \u001b[43mfile_level_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlbl\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlbl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# build final submission aligned to sample_submission.csv\u001b[39;00m\n\u001b[0;32m     36\u001b[0m sub_order \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(SAMPLE_SUB)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munique_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "Cell \u001b[1;32mIn[20], line 10\u001b[0m, in \u001b[0;36mfile_level_predictions\u001b[1;34m(df, boosters, label)\u001b[0m\n\u001b[0;32m      8\u001b[0m swing_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean([bst\u001b[38;5;241m.\u001b[39mpredict(X) \u001b[38;5;28;01mfor\u001b[39;00m bst \u001b[38;5;129;01min\u001b[39;00m boosters], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      9\u001b[0m agg \u001b[38;5;241m=\u001b[39m agg_multiclass \u001b[38;5;28;01mif\u001b[39;00m multiclass \u001b[38;5;28;01melse\u001b[39;00m agg_binary\n\u001b[1;32m---> 10\u001b[0m out \u001b[38;5;241m=\u001b[39m {fid: agg(swing_pred[grp\u001b[38;5;241m.\u001b[39mindex])\n\u001b[0;32m     11\u001b[0m        \u001b[38;5;28;01mfor\u001b[39;00m fid, grp \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile_id\u001b[39m\u001b[38;5;124m\"\u001b[39m)}\n\u001b[0;32m     13\u001b[0m out \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(out)                       \u001b[38;5;66;03m# dict ➜ Series (index = file_id)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m full_idx \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39munique()          \u001b[38;5;66;03m# one entry per file in *this* set\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[20], line 10\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      8\u001b[0m swing_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean([bst\u001b[38;5;241m.\u001b[39mpredict(X) \u001b[38;5;28;01mfor\u001b[39;00m bst \u001b[38;5;129;01min\u001b[39;00m boosters], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      9\u001b[0m agg \u001b[38;5;241m=\u001b[39m agg_multiclass \u001b[38;5;28;01mif\u001b[39;00m multiclass \u001b[38;5;28;01melse\u001b[39;00m agg_binary\n\u001b[1;32m---> 10\u001b[0m out \u001b[38;5;241m=\u001b[39m {fid: \u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mswing_pred\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgrp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m        \u001b[38;5;28;01mfor\u001b[39;00m fid, grp \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile_id\u001b[39m\u001b[38;5;124m\"\u001b[39m)}\n\u001b[0;32m     13\u001b[0m out \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(out)                       \u001b[38;5;66;03m# dict ➜ Series (index = file_id)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m full_idx \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39munique()          \u001b[38;5;66;03m# one entry per file in *this* set\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: agg_binary() missing 1 required positional argument: 'label'"
     ]
    }
   ],
   "source": [
    "# 9️⃣ Predict test set & assemble submission rows (key-aligned)\n",
    "\n",
    "# Cell 9  ▶ test prediction → submission DataFrame\n",
    "def file_level_predictions(df, boosters, label):\n",
    "    multiclass = label in {\"years\", \"level\"}\n",
    "    X = df.drop(columns=DROP_COLS, errors=\"ignore\")\n",
    "\n",
    "    swing_pred = np.mean([bst.predict(X) for bst in boosters], axis=0)\n",
    "    agg = agg_multiclass if multiclass else agg_binary\n",
    "    out = {fid: agg(swing_pred[grp.index])\n",
    "           for fid, grp in df.groupby(\"file_id\")}\n",
    "\n",
    "    out = pd.Series(out)                       # dict ➜ Series (index = file_id)\n",
    "    full_idx = df[\"file_id\"].unique()          # one entry per file in *this* set\n",
    "    out = out.reindex(full_idx)                # adds NaN where a file is missing\n",
    "\n",
    "    if multiclass:\n",
    "        # --------- vector default ----------\n",
    "        stack = np.vstack([v for v in out.dropna()])\n",
    "        default = stack.mean(0) if len(stack) else np.full_like(stack[0], 1/stack.shape[1])\n",
    "\n",
    "        na_mask = out.isna()\n",
    "        if na_mask.any():\n",
    "            out.loc[na_mask] = [default] * na_mask.sum()\n",
    "    else:\n",
    "        # --------- scalar default ----------\n",
    "        out = out.fillna(out.mean())\n",
    "\n",
    "    return out\n",
    "\n",
    "sub_parts = {}\n",
    "for lbl in labels:\n",
    "    sub_parts[lbl] = file_level_predictions(df_test.copy(), models[lbl], lbl)\n",
    "\n",
    "# build final submission aligned to sample_submission.csv\n",
    "sub_order = pd.read_csv(SAMPLE_SUB)[\"unique_id\"]\n",
    "sub = pd.DataFrame(index=sub_order)\n",
    "\n",
    "sub[\"gender\"]               = sub_parts[\"gender\"][sub_order].values\n",
    "sub[\"hold racket handed\"]   = sub_parts[\"handed\"][sub_order].values\n",
    "sub[[\"play years_0\",\"play years_1\",\"play years_2\"]] = \\\n",
    "    np.vstack(sub_parts[\"years\"][sub_order].values)\n",
    "sub[[\"level_2\",\"level_3\",\"level_4\",\"level_5\"]]     = \\\n",
    "    np.vstack(sub_parts[\"level\"][sub_order].values)\n",
    "\n",
    "sub = sub.reset_index().rename(columns={\"index\":\"unique_id\"})\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8848d93-c194-4492-9e4c-4635cd1fca3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sub' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure()\n\u001b[1;32m----> 3\u001b[0m \u001b[43msub\u001b[49m[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgender\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhold racket handed\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mhist(bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40\u001b[39m, layout\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m), figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m3\u001b[39m))\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sub' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "sub[['gender','hold racket handed']].hist(bins=40, layout=(1,2), figsize=(10,3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "949b4561-a3c5-400e-b972-d91c4c41d434",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender NaN rows → 0\n",
      "handed NaN rows → 0\n",
      "years NaN rows → 0\n",
      "level NaN rows → 0\n"
     ]
    }
   ],
   "source": [
    "for lbl in labels:\n",
    "    print(lbl, \"NaN rows →\", sub_parts[lbl].isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4444eec7-3d01-4d16-8a11-2075f554174b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows with NaN : 0\n",
      "gender  mean/min/max : 0.31720518091418004 0.05864428333135692 0.7974459477326536\n",
      "level_2 missing ? 0\n",
      "level_3 missing ? 0\n",
      "level_4 missing ? 0\n",
      "level_5 missing ? 0\n"
     ]
    }
   ],
   "source": [
    "# ▶ local diagnostic\n",
    "bad_rows = sub[sub.isna().any(axis=1)]          # ← axis=1 instead of 1\n",
    "print(\"rows with NaN :\", len(bad_rows))\n",
    "\n",
    "print(\"gender  mean/min/max :\", sub['gender'].mean(),\n",
    "      sub['gender'].min(), sub['gender'].max())\n",
    "\n",
    "for c in ['level_2','level_3','level_4','level_5']:\n",
    "    print(c, \"missing ?\", sub[c].isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5de0e96-199f-4f73-a63b-b63e78464a74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ saved submission_fixed_20250512_161515.csv\n"
     ]
    }
   ],
   "source": [
    "# 🔟 Save CSV for upload\n",
    "\n",
    "# Cell 10  ▶ write CSV\n",
    "fname = f\"submission_fixed_{datetime.now():%Y%m%d_%H%M%S}.csv\"\n",
    "sub.to_csv(fname, index=False, float_format=\"%.10f\")\n",
    "print(\"✅ saved\", fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed9da6b9-5aec-477f-8d97-36e74914d2db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            min          max\n",
      "unique_id           1968.000000  3411.000000\n",
      "gender                 0.058644     0.797446\n",
      "hold racket handed     0.090978     0.700411\n",
      "play years_0           0.116272     0.273286\n",
      "play years_1           0.273394     0.662802\n",
      "play years_2           0.219988     0.586849\n",
      "level_2                0.173141     0.725459\n",
      "level_3                0.025560     0.531704\n",
      "level_4                0.026908     0.132178\n",
      "level_5                0.212171     0.761619\n"
     ]
    }
   ],
   "source": [
    "# ▶ 1. no NaNs\n",
    "assert sub.isna().sum().sum() == 0\n",
    "\n",
    "# ▶ 2. row order identical to sample_submission.csv\n",
    "sample = pd.read_csv(SAMPLE_SUB)\n",
    "assert (sub.columns == sample.columns).all()\n",
    "assert (sub['unique_id'] == sample['unique_id']).all()\n",
    "\n",
    "# ▶ 3. each column has some spread (not all 0 / all 1)\n",
    "print(sub.describe().T[['min','max']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03493d5a-436c-422e-9b67-636f29f9d98e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (AIcup_2025)",
   "language": "python",
   "name": "aicup_2025"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
