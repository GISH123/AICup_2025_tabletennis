{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06d05730",
   "metadata": {},
   "source": [
    "# AIâ€‘CupÂ 2025Â â€“Â Leakâ€‘Free Endâ€‘toâ€‘End Pipeline ğŸ“\n",
    "This single notebook will:\n",
    "1. Extract swingâ€‘level features\n",
    "2. Train LightGBM base models with **GroupKFold(file_id)**\n",
    "3. Save swingâ€‘level probabilities to disk (`swing_level_with_preds.pkl`)\n",
    "4. Train perâ€‘label meta models (mean / max / official rule features) with **GroupKFold**\n",
    "5. Create `submission_meta.csv` containing one row per **unique_id** with probabilities ready for upload.\n",
    "\n",
    "Just set `DATA_DIR` to the folder that contains `train_info.csv` and `train_data/*.txt`, then run all cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b3c5210",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, lightgbm as lgb, warnings, os\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import GroupKFold, train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "DATA_DIR = Path('39_Training_Dataset')  # <- adjust if needed\n",
    "INFO_CSV = DATA_DIR / 'train_info.csv'\n",
    "TXT_DIR  = DATA_DIR / 'train_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30cc07a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_swing(arr: np.ndarray):\n",
    "    Ax,Ay,Az = arr[:,0],arr[:,1],arr[:,2]\n",
    "    Gx,Gy,Gz = arr[:,3],arr[:,4],arr[:,5]\n",
    "    acc = np.linalg.norm(arr[:,:3],1)\n",
    "    gyro= np.linalg.norm(arr[:,3:],1)\n",
    "    return dict(\n",
    "        Ax_mean=Ax.mean(), Ax_std=Ax.std(),\n",
    "        Ay_mean=Ay.mean(), Ay_std=Ay.std(),\n",
    "        Az_mean=Az.mean(), Az_std=Az.std(),\n",
    "        Gx_mean=Gx.mean(), Gx_std=Gx.std(),\n",
    "        Gy_mean=Gy.mean(), Gy_std=Gy.std(),\n",
    "        Gz_mean=Gz.mean(), Gz_std=Gz.std(),\n",
    "        acc_mag_mean=acc.mean(), gyro_mag_mean=gyro.mean(),\n",
    "        acc_vs_gyro_ratio=acc.mean()/(gyro.mean()+1e-6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db0c267c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extract swings: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1955/1955 [00:30<00:00, 64.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset (52785, 21)\n"
     ]
    }
   ],
   "source": [
    "def build_dataset(txt_dir:Path, info_df:pd.DataFrame):\n",
    "    rows=[]\n",
    "    for txt in tqdm(sorted(txt_dir.glob('*.txt')),desc='Extract swings'):\n",
    "        fid=int(txt.stem)\n",
    "        meta=info_df[info_df['unique_id']==fid].iloc[0]\n",
    "        cps=np.fromstring(meta['cut_point'].strip('[]'),sep=' ',dtype=int)\n",
    "        if len(cps)<2: continue\n",
    "        data=np.loadtxt(txt,skiprows=1)\n",
    "        for i in range(len(cps)-1):\n",
    "            swing=data[cps[i]:cps[i+1]]\n",
    "            feats=extract_features_from_swing(swing)\n",
    "            feats.update(file_id=fid,swing_id=i,\n",
    "                         gender=meta['gender'],\n",
    "                         handed=meta['hold racket handed'],\n",
    "                         years=meta['play years'],\n",
    "                         level=meta['level'])\n",
    "            rows.append(feats)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "info_df=pd.read_csv(INFO_CSV)\n",
    "df=build_dataset(TXT_DIR,info_df)\n",
    "print('Dataset',df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b58b52ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split\n",
      "train    36909\n",
      "val       7938\n",
      "test      7938\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "file_ids=df['file_id'].unique()\n",
    "train_ids, test_ids = train_test_split(file_ids,test_size=0.15,random_state=42)\n",
    "train_ids, val_ids  = train_test_split(train_ids,test_size=0.1765,random_state=42)\n",
    "df['split']=df['file_id'].apply(lambda x:'train' if x in train_ids else 'val' if x in val_ids else 'test')\n",
    "print(df['split'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f326575",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lgb(label, multiclass=False):\n",
    "    tr=df[df['split']=='train']\n",
    "    drop=['file_id','swing_id','split','gender','handed','years','level',label]\n",
    "    X=tr.drop(columns=drop)\n",
    "    le=LabelEncoder(); y=le.fit_transform(tr[label])\n",
    "\n",
    "    params=dict(objective='multiclass' if multiclass else 'binary',\n",
    "                metric='multi_logloss' if multiclass else 'auc',\n",
    "                learning_rate=0.05,verbosity=-1,seed=42,\n",
    "                num_class=len(le.classes_) if multiclass else 1)\n",
    "    gkf=GroupKFold(9); groups=tr['file_id'].values\n",
    "    oof=np.zeros((len(tr),len(le.classes_)) if multiclass else len(tr))\n",
    "    models=[]\n",
    "    for tr_idx,va_idx in gkf.split(X,y,groups):\n",
    "        dtrain=lgb.Dataset(X.iloc[tr_idx],y[tr_idx])\n",
    "        dval  =lgb.Dataset(X.iloc[va_idx],y[va_idx])\n",
    "        m=lgb.train(params,dtrain,1000,[dval],callbacks=[lgb.early_stopping(50)])\n",
    "        models.append(m)\n",
    "        oof[va_idx]=m.predict(X.iloc[va_idx])\n",
    "    auc=roc_auc_score(y,oof,multi_class='ovr') if multiclass else roc_auc_score(y,oof)\n",
    "    print(f'{label} OOF AUC {auc:.4f}')\n",
    "    return models,le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c4a3be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[233]\tvalid_0's auc: 0.966146\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[807]\tvalid_0's auc: 0.990947\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[126]\tvalid_0's auc: 0.963629\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[724]\tvalid_0's auc: 0.989121\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[912]\tvalid_0's auc: 0.991284\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[711]\tvalid_0's auc: 0.984612\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[233]\tvalid_0's auc: 0.959846\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[666]\tvalid_0's auc: 0.969303\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[151]\tvalid_0's auc: 0.957755\n",
      "gender OOF AUC 0.9762\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[476]\tvalid_0's auc: 0.999894\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[68]\tvalid_0's auc: 0.99975\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[539]\tvalid_0's auc: 0.999975\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[275]\tvalid_0's auc: 0.999962\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[140]\tvalid_0's auc: 0.999552\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[210]\tvalid_0's auc: 0.999785\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[258]\tvalid_0's auc: 0.999952\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[223]\tvalid_0's auc: 0.999865\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[652]\tvalid_0's auc: 0.999928\n",
      "handed OOF AUC 0.9994\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[994]\tvalid_0's multi_logloss: 0.249113\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[881]\tvalid_0's multi_logloss: 0.21826\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[866]\tvalid_0's multi_logloss: 0.240034\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[997]\tvalid_0's multi_logloss: 0.206096\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[396]\tvalid_0's multi_logloss: 0.352688\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[699]\tvalid_0's multi_logloss: 0.314252\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[840]\tvalid_0's multi_logloss: 0.287417\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[864]\tvalid_0's multi_logloss: 0.314754\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[588]\tvalid_0's multi_logloss: 0.321076\n",
      "years OOF AUC 0.9775\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[619]\tvalid_0's multi_logloss: 0.222699\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[696]\tvalid_0's multi_logloss: 0.206527\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[656]\tvalid_0's multi_logloss: 0.217776\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[583]\tvalid_0's multi_logloss: 0.268575\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[174]\tvalid_0's multi_logloss: 0.377031\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[439]\tvalid_0's multi_logloss: 0.299306\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[514]\tvalid_0's multi_logloss: 0.263408\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[230]\tvalid_0's multi_logloss: 0.366916\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[390]\tvalid_0's multi_logloss: 0.29151\n",
      "level OOF AUC 0.9801\n"
     ]
    }
   ],
   "source": [
    "models_gender, le_gender = train_lgb('gender')\n",
    "models_hand,   le_hand   = train_lgb('handed')\n",
    "models_years,  le_years  = train_lgb('years',True)\n",
    "models_level,  le_level  = train_lgb('level',True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "747f84e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved swing_level_with_preds.pkl\n"
     ]
    }
   ],
   "source": [
    "def predict_swings(models, subset_df, label, le, multiclass=False):\n",
    "    # --- argument sanity check ------------------------------------------------\n",
    "    if not isinstance(label, str):\n",
    "        raise ValueError(\"3Ê³áµˆ arg must be the *label string* (e.g. 'gender').\")\n",
    "    if 'classes_' not in dir(le):\n",
    "        raise ValueError(\"4áµ—Ê° arg must be a scikit-learn LabelEncoder.\")\n",
    "\n",
    "    # --- build feature matrix -------------------------------------------------\n",
    "    base_drop = ['file_id','swing_id','split',\n",
    "                 'gender','handed','years','level', label]\n",
    "\n",
    "    # also drop *any* previously attached prediction columns\n",
    "    extra_drop = [c for c in subset_df.columns if c.startswith('pred_')]\n",
    "    X = subset_df.drop(columns=base_drop + extra_drop)\n",
    "\n",
    "    # --- mean of fold predictions --------------------------------------------\n",
    "    probs = np.mean([m.predict(X) for m in models], axis=0)\n",
    "\n",
    "    # wrap into the expected DataFrame\n",
    "    return (probs, pd.DataFrame({\n",
    "        'file_id': subset_df['file_id'].values,\n",
    "        'true'   : le.transform(subset_df[label].values),\n",
    "        'pred'   : list(probs)                # keep arrays in a single column\n",
    "    }))\n",
    "\n",
    "\n",
    "for label, (mods,le,mc) in {\n",
    "    'gender':(models_gender,le_gender,False),\n",
    "    'handed':(models_hand, le_hand, False),\n",
    "    'years': (models_years,le_years,True),\n",
    "    'level': (models_level,le_level,True)}.items():\n",
    "    df['pred_'+label]=list(predict_swings(mods,df,label,le,mc)[0])\n",
    "\n",
    "df.to_pickle('swing_level_with_preds.pkl')\n",
    "print('Saved swing_level_with_preds.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e631d4-38a6-4701-b21a-7d6b7efe69dd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Test set check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "163f870a-954b-4de6-9490-b0384b19cc3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val gender AUC: 0.9809016393442622\n"
     ]
    }
   ],
   "source": [
    "def official_file_probs(pred_df, multiclass=False):\n",
    "    out=[]\n",
    "    for fid,grp in pred_df.groupby('file_id'):\n",
    "        if multiclass:\n",
    "            p=np.stack(grp['pred'].values)\n",
    "        else:\n",
    "            p_raw=grp['pred'].values.astype(float)\n",
    "            p=np.stack([1-p_raw, p_raw],1)\n",
    "        winner=np.argmax(p.sum(0))\n",
    "        best=p[np.argmax(p[:,winner])]\n",
    "        out.append((fid, grp['true'].iloc[0], best))\n",
    "    ids, y_true, probs = zip(*out)\n",
    "    y_true=np.array(y_true); probs=np.stack(probs)\n",
    "    auc = roc_auc_score(y_true, probs, multi_class='ovr') if multiclass else roc_auc_score(y_true, probs[:,1])\n",
    "    return auc\n",
    "\n",
    "val_df=df[df['split']=='val']\n",
    "print(\"Val gender AUC:\", official_file_probs(predict_swings(models_gender,val_df,'gender',le_gender)[1], False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d5a2031-fe80-4a3e-a27c-b6d08680ff20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val hand AUC: 1.0\n",
      "Val years AUC: 0.9898643524101773\n"
     ]
    }
   ],
   "source": [
    "print(\"Val hand AUC:\", official_file_probs(predict_swings(models_hand,val_df,'handed',le_hand)[1], False))\n",
    "print(\"Val years AUC:\", official_file_probs(predict_swings(models_years,val_df,'years',le_years)[1], True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cdda4617-754c-40b4-b056-0225686b3198",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val level AUC: 0.9967153213683777\n"
     ]
    }
   ],
   "source": [
    "print(\"Val level AUC:\", official_file_probs(predict_swings(models_level,val_df,'level',le_level)[1], True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df3c3d67-2b72-4120-8b51-5b5564a0a47e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df = df[df['split'] == 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4bab12b1-a934-4fab-a9cb-ac58c5c7de32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_preds_gender = predict_swings(models_gender, test_df, 'gender', le_gender, multiclass=False)[1]\n",
    "test_preds_hand   = predict_swings(models_hand,   test_df,  'handed', le_hand, multiclass=False)[1]\n",
    "test_preds_years  = predict_swings(models_years,  test_df,  'years', le_years,  multiclass=True)[1]\n",
    "test_preds_level  = predict_swings(models_level,  test_df,  'level', le_level,  multiclass=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62f096ec-e797-40e7-a572-3bef0f3baf82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test gender AUC: 0.9830820476858345\n",
      "Test handed AUC: 0.9998334027488547\n",
      "Test years AUC: 0.9908969370750618\n",
      "Test level AUC: 0.99938161297444\n"
     ]
    }
   ],
   "source": [
    "print(\"Test gender AUC:\", official_file_probs(test_preds_gender, multiclass=False))\n",
    "print(\"Test handed AUC:\", official_file_probs(test_preds_hand,   multiclass=False))\n",
    "print(\"Test years AUC:\",  official_file_probs(test_preds_years,  multiclass=True))\n",
    "print(\"Test level AUC:\",  official_file_probs(test_preds_level,  multiclass=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db02020f-113d-454c-8da6-719d3be5a081",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6d1da1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta gender AUC 0.9995\n",
      "Meta handed AUC 1.0000\n",
      "Meta years AUC 0.9990\n",
      "Meta level AUC 0.9998\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "labels={'gender':False,'handed':False,'years':True,'level':True}\n",
    "meta_models={}\n",
    "def build_meta(label,mc):\n",
    "    feats,y,groups=[],[],[]\n",
    "    for fid,grp in df.groupby('file_id'):\n",
    "        p=np.stack(grp['pred_'+label].values)\n",
    "        if not mc: p=p.reshape(-1,1)\n",
    "        feats.append(np.concatenate([p.mean(0),p.max(0),p[p.sum(1).argmax()]]))\n",
    "        y.append(grp[label].iloc[0]); groups.append(fid)\n",
    "    return np.vstack(feats),np.array(y),np.array(groups)\n",
    "\n",
    "for label,mc in labels.items():\n",
    "    X,y,g=build_meta(label,mc)\n",
    "    n_class = len(np.unique(y))\n",
    "    oof = np.zeros((len(y), n_class) if mc else len(y))\n",
    "    gkf=GroupKFold(9)\n",
    "    for tr,va in gkf.split(X,y,g):\n",
    "        clf=LogisticRegressionCV(max_iter=1000,multi_class='multinomial' if mc else 'auto',cv=3)\n",
    "        clf.fit(X[tr],y[tr])\n",
    "        pro=clf.predict_proba(X[va])\n",
    "        if not mc: pro=pro[:,1]\n",
    "        oof[va]=pro\n",
    "    auc=roc_auc_score(y,oof,multi_class='ovr') if mc else roc_auc_score(y,oof)\n",
    "    print(f'Meta {label} AUC {auc:.4f}')\n",
    "    final=LogisticRegressionCV(max_iter=1000,multi_class='multinomial' if mc else 'auto',cv=5)\n",
    "    final.fit(X,y)\n",
    "    meta_models[label]=final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23072964-4903-4e4b-b403-cf2f7253b4c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ce198c45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission_meta.csv saved (294, 10)\n"
     ]
    }
   ],
   "source": [
    "# records=[]\n",
    "# for fid,grp in df[df['split']=='test'].groupby('file_id'):\n",
    "#     rec={'unique_id':int(fid)}\n",
    "#     for label,mc in labels.items():\n",
    "#         p=np.stack(grp['pred_'+label].values)\n",
    "#         if not mc: p=p.reshape(-1,1)\n",
    "#         feat=np.concatenate([p.mean(0),p.max(0),p[p.sum(1).argmax()]]).reshape(1,-1)\n",
    "#         pro=meta_models[label].predict_proba(feat)[0]\n",
    "#         if mc:\n",
    "#             for k,pr in enumerate(pro): rec[f'{label}_{k}']=pr\n",
    "#         else:\n",
    "#             rec[f'{label}_prob']=pro[1]\n",
    "#     records.append(rec)\n",
    "# sub=pd.DataFrame(records).sort_values('unique_id')\n",
    "# sub.to_csv('submission_meta.csv',index=False)\n",
    "# print('submission_meta.csv saved',sub.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35523cb-c526-4212-b416-c1165f7713f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (AIcup_2025)",
   "language": "python",
   "name": "aicup_2025"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
